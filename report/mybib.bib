@book { rl-book,
  author = {R. S. Sutton and A. G. Barto}, 
  title = {{Reinforcement Learning: An Introduction}},
  publisher = {MIT Press},
  year = 1998,
  edition = {1st}
}

@article { q-learning,
  author = {C. J. C. H. Watkins and P. Dayan}, 
  title = {{Q-Learning}},
  journal = {Machine Learning},
  year = 1992,
  pages = {279-292},
  volume = 8
}

@article { challenges-of-rl,
  author = {R. S. Sutton}, 
  title = {{Introduction: The Challenges of Reinforcement Learning}},
  journal = {Machine Learning},
  year = 1992,
  pages = {225-227},
  volume = 8
}

@article { atari,
  author = {V. Mnih and K. Kavukcuoglu and D. Silver and A. Graves and I. Antonoglou and D. Wierstra and M. Riedmiller},
  title = {{Playing Atari with Deep Reinforcement Learning}},
  journal = {arXiv preprint arXiv:1312.5602},
  year = 2013
}

@article { backgammon,
  author = {G. Tesauro}, 
  title = {{Temporal Difference Learning and TD-Gammon}},
  journal = {Communications of the ACM},
  year = 1995,
  pages = {58-68},
  volume = 38
}

@article { go,
  author = {D. Silver and A. Huang and C. J. Maddison and A. Guez and L. Sifre and G. van den Driessche and J. Schrittwieser and I. Antonoglou and V. Panneershelvam and M. Lanctot and S. Dieleman and D. Grewe and J. Nham and N. Kalchbrenner and I. Sutskever and T. Lillicrap and M. Leach and K. Kavukcuoglu and T. Graepel and D. Hassabis}, 
  title = {{Mastering the Game of Go Without Human Knowledge}},
  journal = {Nature},
  year = 2016,
  pages = {484-489},
  volume = 529
}

@book{ winning-ways-math-plays,
  author = {E. R. Berlokamp and J. H. Conway and R. K. Guy}, 
  title = {Winning Ways for Your Mathematical Plays},
  publisher = {A K Peters, Ltd.},
  year = 2003,
  volume = 2,
  edition = {2nd}
}

@book { tic-tac-toe-rules,
  author = {P. D. Schumer}, 
  title = {Mathematical Journeys},
  publisher = {Wiley-Interscience},
  year = 2004,
  edition = {1st}
}

@article { nim-rules,
  author = {C. L. Bouton}, 
  title = {{Nim, a Game with a Complete Mathematical Theory}},
  journal = {Annals of Mathematics},
  year = {1901-1902},
  number = {1/4},
  pages = {35-39},
  volume = 3
}

@misc { chung-toi-rules,
  author = {E. Cubukcuoglu},
  title = {{Unofficial Chung Toi Rules}},
  howpublished = {\url{https://boardgamegeek.com/filepage/51629/unofficial-chung-toi-rules}}
}

@misc { chung-toi-mensa,
  title = {{Mensa Select Winners}},
  howpublished = {\url{https://mensamindgames.com/about/winning-games/}}
}

@inproceedings { chung-toi-rl,
  author = {C. J. Gatti and J. D. Linton and M. J. Embrechts},
  booktitle = {European Symposium on Artificial Neural Networks, Computational Intelligence and Machine Learning},
  title = {{A Brief Tutorial on Reinforcement Learning: The Game of Chung Toi}},
  year = 2011,
  pages = {129-134}
}

@inproceedings { chung-toi-params,
  author = {C. J. Gatti and M. J. Embrechts and J. D. Linton},
  booktitle = {2011 IEEE International Conference on Systems, Man, and Cybernetics},
  title = {{Reinforcement Learning and the Effects of Parameter Settings in the Game of Chung Toi}},
  year = 2011,
  pages = {3530-3535},
}

@article { meta-learning-rl,
  author = {N. Schweighofer and K. Doya}, 
  title = {{Meta-Learning in Reinforcement Learning}},
  journal = {Neural Networks},
  year = 2003,
  number = 1,
  pages = {5-9},
  volume = 16
}

@article { exploration-exploitation-meta-param,
  author = {S. Ishii and W. Yoshida and J. Yoshimoto }, 
  title = {{Control of Exploitation-Exploration Meta-Parameter in Reinforcement Learning}},
  journal = {Neural Networks},
  year = 2002,
  number = {4-6},
  pages = {665-687},
  volume = 15
}

@inproceedings { meta-param-evolution, 
  author = {A. Eriksson and G. Capi and K. Doya},
  booktitle = {IEEE/RSJ International Conference on Intelligent Robots and Systems},
  title = {Evolution of Meta-Parameters in Reinforcement Learning Algorithm},
  year = 2003,
  volume = 1,
  pages = {412-417}
}

@inproceedings { meta-optimization,
  author = {J. Branke and J. A. Elomari},
  booktitle = {14th Annual Conference on Genetic and Evolutionary Computation},
  title = {Meta-Optimization for Parameter Tuning with a Flexible Computing Budget},
  series = {GECCO '12},
  year = 2012,
  pages = {1245-1252},
  publisher = {ACM}
} 

@article { exploration-exploitation-meta-param,
  author = {S. Ishii and W. Yoshida and J. Yoshimoto}, 
  title = {{Control of Exploitation-Exploration Meta-Parameter in Reinforcement Learning}},
  journal = {Neural Networks},
  year = 2002,
  number = {4-6},
  pages = {665-687},
  volume = 15
}

@inproceedings { open-rl-questions,
  author = {R. S. Sutton},
  editor = {P. Fischer and H. U. Simon},
  title = {Open Theoretical Questions in Reinforcement Learning},
  booktitle = {Computational Learning Theory},
  year = 1999,
  pages = {11-17}
}

@article { mdp-convergence,
  author = {S. Singh and T. Jaakkola and M. L. Littman and C. Szepesvari}, 
  title = {{Convergence Results for Single-Step On-Policy Reinforcement-Learning Algorithms}},
  journal = {Machine Learning},
  year = 2000,
  number = 3,
  pages = {287-308},
  volume = 38
}

@article { rl-a-survey,
  author = {L. P. Kaelbling and M. L. Littman and A. W. Moore}, 
  title = {{Reinforcement Learning: A Survey}},
  journal = {Journal of Artificial Intelligence Research},
  year = 1996,
  pages = {237-285},
  volume = 4
}
